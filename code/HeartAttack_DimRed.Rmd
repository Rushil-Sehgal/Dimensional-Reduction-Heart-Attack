---
title: "Project_Dimension_4830"
output: html_document
date: '2022-10-27'

ref: - https://www.analyticsvidhya.com/blog/2016/03/pca-practical-guide-principal-component-analysis-python/
     - https://www.statology.org/confusion-matrix-in-r/
---
## Loading Libraries
```{r}
library(corrplot)
library(RColorBrewer)
library(car)
library(Metrics)
library(ggplot2)
library(plotrix)
library(tidyverse)
library(here)
library(skimr)
library(janitor)
library(lubridate)
library(LaplacesDemon)
library(WVPlots)
library(praznik)
library(clusterSim)
library(dplyr)
library(reshape2)
library(olsrr)
library(caTools)
library(ggcorrplot)
library(Metrics)
library(modelr)
library(Amelia)
library(Hmisc)
library(scatr)
library(moments)
library(OneR)
library(ggpubr)
library(rcompanion)
library(factoextra)
library(psych)
library(randomForest)
library(AUC)
library(caret)
library(ISLR)
```

#Loading dataset
```{r}
df_heart<- read.csv("heart.csv")
head(df_heart)
```

#EDA
```{r}
summary(df_heart)
```

thal: A blood disorder called thalassemia Value 0: NULL (dropped from the dataset previously
Value 1: fixed defect (no blood flow in some part of the heart)
Value 2: normal blood flow
Value 3: reversible defect (a blood flow is observed but it is not normal)

caa-0 to 3: Number of major vessels 

```{r}
str(df_heart)
```

```{r}
dim(df_heart)
```


#Missing values

```{r}
colSums(is.na(df_heart))
```


```{r}
missmap(df_heart, col=c('black','grey'),legend=FALSE)
```

#Boxplots
```{r}
ggplot(df_heart, aes(thall)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(caa)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(slp)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(oldpeak)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(exng)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(thalachh)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(restecg)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(fbs)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(chol)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(trtbps)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
ggplot(df_heart, aes(cp)) + 
  geom_boxplot(outlier.colour = "red", outlier.size = 3, outlier.shape = 8)
```

#Correlation
```{r}
corr_heart <- cor(df_heart)
corr_heart
```

#Correlation Plot
```{r}
corrplot(corr_heart, method="circle")
```

# Verifying the label proportion in target variable
```{r}
library(janitor)
tabyl(df_heart, output)
tabyl(df_heart, sex)
```

We can see we have nearly equal proportion of labels in our target variable.

## Below plot is showing the heart issues with respect to the gender where females tend to have more risk to heart failure. 

```{r}
library(CGPfunctions)
PlotXTabs2(df_heart,sex,output,results.subtitle=FALSE) 
```

# Model Creation without Dimension Reduction
```{r}
partition <- sample(c(TRUE, FALSE), nrow(df_heart), replace=TRUE, prob=c(0.8,0.2))
df_heart_train <- df_heart[partition, ]
df_heart_test <- df_heart[!partition, ]
```

```{r}
dim(df_heart_train)
dim(df_heart_test)
```

#Logistic Model
```{r}
log_model <- glm(output ~., data = df_heart_train, family = binomial)
```

```{r}
coef(log_model)
summary(log_model)$coef
```

```{r}
prediction_from_test = predict(log_model, newdata = df_heart_test, type = "response")
prediction_output <- ifelse(prediction_from_test>0.5, 1,0)
prediction_output <- as.factor(prediction_output)
df_predict <- data.frame(table(as.factor(df_heart_test$output), prediction_output))
#ggplot(df_predict, aes(x=df_heart_test$output, y=prediction_output)) + geom_point() + geom_smooth()
cfm <- confusionMatrix(as.factor(df_heart_test$output),prediction_output)
cfm
fourfoldplot(cfm$table)
```

```{r}
mis_error <- mean(prediction_output != df_heart_test$output)
print(paste('Accuracy',1-mis_error))
```

#Dimension Reduction

#Barlett's Test
```{r}
heart.correlations = cor(df_heart_train)
cortest.bartlett(corr_heart, n = nrow(df_heart_train))
```

Barlett's Test is used to check if there is any correlation between the variables that can be accommodated in few number of factors. The p-value generated by the test fulfills either of the hypothesis:
  Null Hypothesis - Variables are not correlated
  Alternate Hypothesis - Variables are correlated
  
From the result of Barlett Test, we can see that the p-value is 0 which less than the default significant value of 0.05. Hence, we can reject the Null Hypothesis and consider that the variables are correlated and can be used for factor analysis.

#KMO
```{r}
KMO(corr_heart)
```

KMO Test is used to measure the sampling adequency of the data in order to calculate the measure of factorability. As per the default cutoff value, any value greater than equal to KMO=60, can be considered suitable for factor analysis.

However, the value for the KMO test came out to be 0.65, which tells us that factor analysis can be conducted on the data.

## PCA with scaling = True

```{r}
heart.pca <- prcomp(df_heart_train, scale = TRUE,center = TRUE)
summary(heart.pca)
heart.pca
```

#compute variance of each principal component
```{r}
pr_var <- (heart.pca$sdev)^2
pr_var
```

We aim to find the components which explain the maximum variance. This is because, we want to retain as much information as possible using these components. So, higher is the explained variance, higher will be the information contained in those components.

#proportion of variance explained
# ```{r}
# prop_varex <- pr_var/sum(pr_var)
# prop_varex
# ```

Above output shows that first PC explains 23.5% variance. Second component explains 11.2% and so on.

#ScreePlot for determining PC to keep
```{r}
#screeplot(heart.pca, main ="Scree Plot", xlab="Components",npcs = 50)
screeplot(heart.pca, main="Scree Plot", type="line",npcs = 50)
legend("topright", legend = c("Eigen Value = 0.7"))
abline(h = 0.7, col = "red", lty = 5)
fviz_eig(heart.pca,ncp = 50)
```
The plot shows around 9 components explains most of the variance in the dataset. We can also say that we have reduced the number of attributes from 14 to 9.

```{r}
fit_heart <- principal(df_heart_train, nfactors=9, rotate="varimax")
fit_heart$loadings
```

Cumulative Variance comes out to be around ~83%


```{r}
fit_heart
```

# below we can see we reduced dimensions of our dataset with same number of rows/observations.

```{r}
print(fit_heart$n.obs)
print(fit_heart$factors)
```

```{r}
# biplot(fit_heart$loadings[,0:2])
```
The parameter scale = 0 ensures that arrows are scaled to represent the loadings. To make inference from image above, focus on the extreme ends (top, bottom, left, right) of this graph.

We infer than first principal component corresponds to a measure of thalachh, slp. Similarly, it can be said that the second component corresponds to a measure of chol, age, trbps. For exact measure of a variable in a component, you should look at rotation matrix(above) again.


After we’ve performed PCA on training set, let’s now understand the process of predicting on test data using these components. The process is simple. Just like we’ve obtained PCA components on training set, we’ll get another bunch of components on testing set. Finally, we train the model.

But, few important points to understand:

We should not combine the train and test set to obtain PCA components of whole data at once. Because, this would violate the entire assumption of generalization since test data would get ‘leaked’ into the training set. In other words, the test data set would no longer remain ‘unseen’. Eventually, this will hammer down the generalization capability of the model.
We should not perform PCA on test and train data sets separately. Because, the resultant vectors from train and test PCAs will have different directions ( due to unequal variance). Due to this, we’ll end up comparing data registered on different axes. Therefore, the resulting vectors from train and test data should have same axes.


So, what should we do?

We should do exactly the same transformation to the test set as we did to training set, including the center and scaling feature. Let’s do it in R:


#add a training set with nine principal components
```{r}
train.data <- data.frame(output = df_heart_train$output, heart.pca$x[,0:9])
```

```{r}
train.data
#biplot(train.data[,1:3],train.data[,0])
```


# Lets run a decision tree model 
```{r}
#install.packages("rpart")
library(rpart)
rpart.model <- rpart(df_heart_train$output ~ .,data = train.data, method = "anova")
rpart.model
```

#transform test into PCA
```{r}
test.data <- predict(heart.pca , newdata = df_heart_test)
test.data <- as.data.frame(test.data)
test.data
```

# select first 9 components
```{r}
test.data <- test.data[,0:9]
test.data <- as.data.frame(test.data)
test.data
```

#make prediction on test data

```{r}
rpart.prediction <- predict(rpart.model, test.data)
rpart.prediction <- ifelse(rpart.prediction>0.5,1,0)
rpart.prediction <- as.factor(rpart.prediction)
```

```{r}
confusionMatrix(as.factor(df_heart_test$output), rpart.prediction)
cfm_pca <- confusionMatrix(as.factor(rpart.prediction),as.factor(df_heart_test$output))
cfm_pca
fourfoldplot(cfm_pca$table)
```

#find optimal cutoff probability to use to maximize accuracy
```{r}
#library(cutpointr)
#optimal <- cutpointr(df_heart_test$output, rpart.prediction)
#summary(optimal)
```

#calculate total misclassification error rate

```{r}
#misClassError(df_heart_test$output, rpart.prediction, threshold=optimal)
```

As we can see the total mis-classification rate of our model trained on Principal components is just 0.03( ~ 3% ), meaning this model will better perform on predictions whether an individual will get the heart disease or not.


# Now we will explore the Exploratory Factor Analysis on our dataset
### As in previous steps using PCA, we have reduced the dimensionality of the dataset but with factor analysis we wil get the insights about the covariances or correlations between the variables.

```{r}
nofactors = fa.parallel(df_heart, fm="ml", fa="fa")
nofactors$fa.values#eigen values
```


```{r}
head(df_heart)
EFA_model <- fa(df_heart,nfactors = 5, scale=TRUE, rotate = "varimax", fm = "ml")
fa.diagram(EFA_model)
```


```{r}
EFA_model$loadings
print(EFA_model)
```

```{r}
library(GPArotation)
EFA_model_two <- fa(df_heart, nfactors = 5, rotate = "oblimin")
fa.diagram(EFA_model_two)
```

```{r}
EFA_model_two$loadings
```

```{r}
EFA_model_two
```

MR1 and MR2 are factors

h2: the amount of variance in the item/variable explained by the (retained) factors. It is the sum of the squared loadings

u2 or uniqueness: 1 - h2. residual variance

com: Item complexity.It equals one if an item loads only on one factor, 2 if evenly loads on two factors, etc. Basically it tells you how much an item reflects a single construct. It will be lower for relatively lower loadings.


```{r}
#look at loadings
print(EFA_model$loading, cutoff = 0.4)

```
```{r}
#communality
EFA_model
```

# LDA

# Finding the correlations between features.

```{r}
ggcorrplot(corr_heart, hc.order = FALSE, tl.srt = 90, outline.color = 'white') + geom_tile(fill="black") +
  geom_tile(height=0.9, width=0.9)
```


```{r}
lda.heart <- lda(output~., data=df_heart_train)
lda.heart
```

```{r}
pred.heart <- predict(lda.heart)
print(pred.heart$class)
```

```{r}
df_heart_train1 <- df_heart_train
```



```{r}
df_heart_train1$output[df_heart_train1$output==1]='Yes'
df_heart_train1$output[df_heart_train1$output==0]='No'
#df_employee$Attrition=as.numeric(df_employee$Attrition)
```

```{r}
df_heart_train1$output
```

```{r}
summary(pred.heart$class)
xtab <- table(pred.heart$class, df_heart_train$output)
print(xtab)
caret::confusionMatrix(xtab, positive = "1")
cfm_lda <- confusionMatrix(as.factor(pred.heart$class),as.factor(df_heart_train$output))
cfm_lda
fourfoldplot(cfm_lda$table)
```

# Correspondence Analysis

```{r}
str(df_heart)
```

# Converting Categorical
```{r}
factor_name <- c('sex','cp','fbs','restecg','exng','slp','caa','thall','output')
df_heart_ca = df_heart
df_heart_ca[,factor_name] <- lapply(df_heart[,factor_name] , factor)
```

```{r}
str(df_heart_ca)
```


```{r}
library(FactoMineR)
library(factoextra)
#head(df_heart_ca[,c("slp","caa")])
harper_table <- table(df_heart_ca$slp, df_heart_ca$caa)
harper_table <- harper_table[,colSums(harper_table) > 1]
CA_harper <- CA(harper_table,graph = F)
plot(CA_harper)
#ca_model
```





